"""
Promty AI Server - FastAPI ê¸°ë°˜ Python AI ì„œë²„
Backend (NestJS)ì—ì„œ ìš”ì²­ì„ ë°›ì•„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µ
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import logging
import os
from datetime import datetime

# ================== ë¡œê¹… ì„¤ì • ==================

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - [%(name)s] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ================== FastAPI ì•± ì´ˆê¸°í™” ==================

app = FastAPI(
    title="Promty AI Server",
    version="1.0.0",
    description="Frontend â†’ Backend â†’ AI Server í†µì‹ "
)

# âœ… CORS ì„¤ì • (Backendì—ì„œ ìš”ì²­ ê°€ëŠ¥)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:3001",
        "http://localhost:3333",
        "*"  # ê°œë°œ í™˜ê²½ìš© (í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œê±°)
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================== Request/Response ëª¨ë¸ ==================

class GeneratePromptRequest(BaseModel):
    prompt: str  # âœ… Frontend/Backendì—ì„œ "prompt" í•„ë“œë¡œ ë³´ëƒ„
    tone: Optional[str] = "neutral"

class GeneratePromptResponse(BaseModel):
    generatedPrompt: str
    model: str = "promty-ai-server-v1"

class ChatMessageRequest(BaseModel):
    message: str  # âœ… Frontend/Backendì—ì„œ "message" í•„ë“œë¡œ ë³´ëƒ„

class ChatMessageResponse(BaseModel):
    reply: str
    model: str = "promty-ai-server-v1"

class PromptItem(BaseModel):
    id: str
    title: str
    description: str
    category: str
    rating: float
    usageCount: int

# ================== í—¬ìŠ¤ ì²´í¬ ==================

@app.get("/health")
async def health_check():
    logger.info("[GET /health] í—¬ìŠ¤ ì²´í¬ ìš”ì²­")
    return {
        "status": "ok",
        "service": "Promty AI Server",
        "timestamp": datetime.now().isoformat()
    }

# ================== í”„ë¡¬í”„íŠ¸ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ ==================

@app.post("/generate", response_model=GeneratePromptResponse)
async def generate_prompt(req: GeneratePromptRequest):
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„± API
    Backendê°€ POST /ai/generate-prompt â†’ AI Server POST /generateë¡œ ì „ë‹¬
    """
    # ğŸ”´ ì§„ì…ì  ë¡œê¹…
    logger.info(f"[POST /generate] ğŸ“¤ START - ìš”ì²­ ìˆ˜ì‹ ")
    logger.info(f"[POST /generate] ğŸ“¥ Payload: {req.dict()}")
    logger.info(f"[POST /generate] ğŸ“¥ prompt field: '{req.prompt}'")
    logger.info(f"[POST /generate] ğŸ“¥ tone field: '{req.tone}'")

    try:
        
        user_prompt = req.prompt
        tone = req.tone or "neutral"

        logger.info(f"[POST /generate] ğŸ”„ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")
        logger.info(f"  - user_prompt: {user_prompt[:50]}..." if len(user_prompt) > 50 else f"  - user_prompt: {user_prompt}")
        logger.info(f"  - tone: {tone}")
        
    except Exception as e:  # ğŸ‘ˆ ì´ ë¶€ë¶„ ì¶”ê°€!
        print(f"ì—ëŸ¬ ë°œìƒ: {e}")
        return {"error": str(e)}
    try:
        user_prompt = req.prompt
        tone = req.tone or "neutral"

        logger.info(f"[POST /generate] ğŸ”„ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")
        logger.info(f"  - user_prompt: {user_prompt[:50]}..." if len(user_prompt) > 50 else f"  - user_prompt: {user_prompt}")
        logger.info(f"  - tone: {tone}")

        logger.debug(f"[POST /generate] ğŸ“¡ AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")

        # âœ… AI ë¡œì§ (í˜„ì¬ëŠ” í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±, ì‹¤ì œ LLM ì—°ë™ ì‹œ êµì²´)
        generated = f"""ë‹¹ì‹ ì€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìƒí™©ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”:

[ì‚¬ìš©ì ì…ë ¥]
{user_prompt}

[ì‘ë‹µ ê°€ì´ë“œ]
ë‹¤ìŒ êµ¬ì¡°ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
1. ìƒí™© ë¶„ì„ (3-5ì¤„)
2. êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ (3ê°€ì§€ ì´ìƒ)
3. ì˜ˆìƒë˜ëŠ” ì¥ë‹¨ì 
4. ì‹¤í–‰ ë‹¨ê³„ë³„ ê°€ì´ë“œ

[í†¤]
{tone}

[ì¶”ê°€ ì§€ì‹œì‚¬í•­]
- ë‹µë³€ì€ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
- ì¥ê¸°ì  ê´€ì ê³¼ ë‹¨ê¸°ì  ê´€ì ì„ ëª¨ë‘ ê³ ë ¤í•´ì£¼ì„¸ìš”."""

        response = GeneratePromptResponse(generatedPrompt=generated)

        logger.info(f"[POST /generate] âœ… AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"[POST /generate] ğŸ“¦ Generated prompt size: {len(generated)} characters")

        return response

    except Exception as e:
        logger.error(f"[POST /generate] âŒ FAILED - ì—ëŸ¬ ë°œìƒ")
        logger.error(f"[POST /generate] âŒ Error Type: {type(e).__name__}")
        logger.error(f"[POST /generate] âŒ Error Message: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ================== AI ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ ==================

@app.post("/chat", response_model=ChatMessageResponse)
async def chat(req: ChatMessageRequest):
    """
    AI ì±„íŒ… API
    Backendê°€ POST /ai/chat â†’ AI Server POST /chatë¡œ ì „ë‹¬
    """
    # ğŸ”´ ì§„ì…ì  ë¡œê¹…
    logger.info(f"[POST /chat] ğŸ“¤ START - ìš”ì²­ ìˆ˜ì‹ ")
    logger.info(f"[POST /chat] ğŸ“¥ Payload: {req.dict()}")
    logger.info(f"[POST /chat] ğŸ“¥ message field: '{req.message}'")

    try:
        user_message = req.message

        logger.info(f"[POST /chat] ğŸ”„ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")
        logger.info(f"  - user_message: {user_message[:50]}..." if len(user_message) > 50 else f"  - user_message: {user_message}")

        logger.debug(f"[POST /chat] ğŸ“¡ AI ì‘ë‹µ ìƒì„± ì¤‘...")

        # âœ… AI ëŒ€í™” ë¡œì§ (í˜„ì¬ëŠ” í…œí”Œë¦¿ ê¸°ë°˜, ì‹¤ì œ LLM ì—°ë™ ì‹œ êµì²´)
        reply = f"""ì•ˆë…•í•˜ì„¸ìš”! Promty AIì…ë‹ˆë‹¤.

ë‹¹ì‹ ì´ ë§ì”€í•˜ì‹  '{user_message}'ì— ëŒ€í•´ ë” ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

ì¢€ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?
- íŠ¹ì • ìƒí™©ì— ëŒ€í•œ ì¡°ì–¸ì´ í•„ìš”í•˜ì‹ ê°€ìš”?
- í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
- ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?

ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"""

        response = ChatMessageResponse(reply=reply)

        logger.info(f"[POST /chat] âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        logger.info(f"[POST /chat] ğŸ“¦ Generated reply size: {len(reply)} characters")

        return response

    except Exception as e:
        logger.error(f"[POST /chat] âŒ FAILED - ì—ëŸ¬ ë°œìƒ")
        logger.error(f"[POST /chat] âŒ Error Type: {type(e).__name__}")
        logger.error(f"[POST /chat] âŒ Error Message: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ================== ë§ì¶¤ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸ ==================

@app.post("/recommendations", response_model=List[PromptItem])
async def get_recommendations(context: Optional[str] = None):
    """
    ë§ì¶¤ ì¶”ì²œ API
    Backendê°€ POST /ai/recommendations â†’ AI Server POST /recommendationsë¡œ ì „ë‹¬
    """
    # ğŸ”´ ì§„ì…ì  ë¡œê¹…
    logger.info(f"[POST /recommendations] ğŸ“¤ START - ìš”ì²­ ìˆ˜ì‹ ")
    logger.info(f"[POST /recommendations] ğŸ“¥ context field: {context or '(ì—†ìŒ)'}")

    try:
        logger.info(f"[POST /recommendations] ğŸ”„ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")
        logger.debug(f"[POST /recommendations] ğŸ“¡ ì¶”ì²œ ë°ì´í„° ìƒì„± ì¤‘...")

        # âœ… ì¶”ì²œ ë¡œì§ (í˜„ì¬ëŠ” ê³ ì • ë°ì´í„°, ì‹¤ì œ AI ê¸°ë°˜ ì¶”ì²œ ì‹œ êµì²´)
        recommendations = [
            {
                "id": "1",
                "title": "ChatGPT-4",
                "description": "GPT-4 ê¸°ë°˜ ê³ ê¸‰ AI ëª¨ë¸ - ë³µì¡í•œ ì¶”ë¡ ê³¼ ë¶„ì„ì— ìµœì í™”",
                "category": "í…ìŠ¤íŠ¸ ìƒì„±",
                "rating": 4.8,
                "usageCount": 1250,
            },
            {
                "id": "2",
                "title": "Claude 3 Opus",
                "description": "Anthropicì˜ ê³ ì„±ëŠ¥ AI ëª¨ë¸ - ì°½ì˜ì  ë¬¸ì„œ ì‘ì„±ì— ìš°ìˆ˜",
                "category": "ì½”ë“œ ì‘ì„±",
                "rating": 4.7,
                "usageCount": 980,
            },
            {
                "id": "3",
                "title": "Gemini Pro",
                "description": "Googleì˜ ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ - ëŒ€í™”ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê°€ëŠ¥",
                "category": "ì´ë¯¸ì§€ ë¶„ì„",
                "rating": 4.6,
                "usageCount": 750,
            },
            {
                "id": "4",
                "title": "LLaMA 2",
                "description": "Metaì˜ ì˜¤í”ˆì†ŒìŠ¤ AI ëª¨ë¸ - ë¡œì»¬ ë°°í¬ ê°€ëŠ¥",
                "category": "ì˜¤í”ˆì†ŒìŠ¤",
                "rating": 4.5,
                "usageCount": 620,
            },
            {
                "id": "5",
                "title": "Palm 2",
                "description": "Googleì˜ ê³ ê¸‰ AI ëª¨ë¸ - ë‹¤êµ­ì–´ ì§€ì› ìš°ìˆ˜",
                "category": "ë‹¤êµ­ì–´",
                "rating": 4.4,
                "usageCount": 540,
            },
        ]

        logger.info(f"[POST /recommendations] âœ… ì¶”ì²œ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        logger.info(f"[POST /recommendations] ğŸ“¦ Recommendations count: {len(recommendations)}")
        logger.info(f"[POST /recommendations] ğŸ“¦ Titles: {[r['title'] for r in recommendations]}")

        return recommendations

    except Exception as e:
        logger.error(f"[POST /recommendations] âŒ FAILED - ì—ëŸ¬ ë°œìƒ")
        logger.error(f"[POST /recommendations] âŒ Error Type: {type(e).__name__}")
        logger.error(f"[POST /recommendations] âŒ Error Message: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ================== ì„œë²„ ì‹œì‘ ==================

if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", 8000))
    host = os.getenv("HOST", "0.0.0.0")

    logger.info(f"ğŸš€ Promty AI Server ì‹œì‘")
    logger.info(f"   Address: http://{host}:{port}")
    logger.info(f"   API Docs: http://localhost:{port}/docs")
    logger.info(f"   Health Check: http://localhost:{port}/health")

    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="debug"
    )
